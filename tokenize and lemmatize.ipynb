{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99bdc63c-ec3f-44c8-8bd2-7b722c6c791c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f6dd33d-9d63-45b7-b832-deaa3442100d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'there',\n",
       " ',',\n",
       " 'how',\n",
       " 'are',\n",
       " 'you',\n",
       " '.',\n",
       " 'Where',\n",
       " 'do',\n",
       " 'you',\n",
       " 'live',\n",
       " '.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize=nltk.word_tokenize(\"Hello there ,how are you. Where do you live.\")\n",
    "tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99c796ce-68b4-44e7-baa8-acc388fbd304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello there ,how are you.', 'Where do you live.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_token=nltk.sent_tokenize(\"Hello there ,how are you. Where do you live.\")\n",
    "sent_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a20358e2-2d92-461f-ad21-4c6294157760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello there, how are you . Where do you live.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "de_tokenize=TreebankWordDetokenizer().detokenize(tokenize)\n",
    "de_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b644ef0-adb7-4268-953b-90b4afde1ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#python -m spacy info\n",
    "#pip install -U spacy\n",
    "#pip install -U pydantic\n",
    "#python -m spacy download en_core_web_sm\n",
    "#pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "42a8eee8-78ba-4fc2-a2f6-5a3475002eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'there', ',', 'how', 'are', 'you', '.', 'Where', 'do', 'you', 'live', '.']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp=spacy.load('en_core_web_sm')\n",
    "text=\"Hello there ,how are you. Where do you live.\"\n",
    "doc=nlp(text)\n",
    "#for token in doc:\n",
    "#    print(token)\n",
    "print([token.text for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dbec157b-8af0-433e-929d-711b7b05afde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello there ,\n",
      "Where do you\n",
      "Tell me you\n",
      "Where do you\n",
      "What is you\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp=spacy.load('en_core_web_sm')\n",
    "text=\"Hello there, how are you. Where do you live.Tell me you name.Where do you work for living.What is you rent\"\n",
    "doc=nlp(text)\n",
    "for sent in doc.sents:\n",
    "    #print(sent)\n",
    "    print(sent[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3ce1ff43-9129-4947-b0ce-e520135b96e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3d9022dd-d76b-4bdc-b798-b0d719aed1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey---->hey\n",
      "you---->you\n",
      "peoples---->people\n",
      "how---->how\n",
      "are---->are\n",
      "you---->you\n",
      "doing---->doing\n",
      "your---->your\n",
      "working---->working\n",
      ".---->.\n",
      "Saying---->Saying\n",
      "the---->the\n",
      "word---->word\n",
      "is---->is\n",
      "improving---->improving\n",
      "the---->the\n",
      "decisions---->decision\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Mohammed\n",
      "[nltk_data]     Arif\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\Mohammed\n",
      "[nltk_data]     Arif\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lem=WordNetLemmatizer()\n",
    "sen='hey you peoples how are you doing your working. Saying the word is improving the decisions'\n",
    "sen_token=nltk.word_tokenize(sen)\n",
    "for x in sen_token:\n",
    "    print(x + '---->' + lem.lemmatize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5fc400a2-48ff-4d4b-a4f5-937fa608040b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hey you people how are you doing your working . Saying the word is improving the decision'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lem=WordNetLemmatizer()\n",
    "sen='hey you peoples how are you doing your working. Saying the word is improving the decisions'\n",
    "sen_token=nltk.word_tokenize(sen)\n",
    "t=\" \".join([lem.lemmatize(x) for x in sen_token])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "10138620-ba9b-46b2-a7cc-d4e5179212aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saying the word is improving the decisions\n"
     ]
    }
   ],
   "source": [
    "#!pip install textblob\n",
    "from textblob import TextBlob,Word\n",
    "word='Saying the word is improving the decisions'\n",
    "w=Word(word)\n",
    "print(w.lemmatize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5261cd4-4ad2-4d10-9f74-ded5652c3e81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
